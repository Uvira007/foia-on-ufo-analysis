<!DOCTYPE html>
<html>
<head>
<title>checkpoint-2.md</title>
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">

<style>
/* https://github.com/microsoft/vscode/blob/master/extensions/markdown-language-features/media/markdown.css */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

body {
	font-family: var(--vscode-markdown-font-family, -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif);
	font-size: var(--vscode-markdown-font-size, 14px);
	padding: 0 26px;
	line-height: var(--vscode-markdown-line-height, 22px);
	word-wrap: break-word;
}

#code-csp-warning {
	position: fixed;
	top: 0;
	right: 0;
	color: white;
	margin: 16px;
	text-align: center;
	font-size: 12px;
	font-family: sans-serif;
	background-color:#444444;
	cursor: pointer;
	padding: 6px;
	box-shadow: 1px 1px 1px rgba(0,0,0,.25);
}

#code-csp-warning:hover {
	text-decoration: none;
	background-color:#007acc;
	box-shadow: 2px 2px 2px rgba(0,0,0,.25);
}

body.scrollBeyondLastLine {
	margin-bottom: calc(100vh - 22px);
}

body.showEditorSelection .code-line {
	position: relative;
}

body.showEditorSelection .code-active-line:before,
body.showEditorSelection .code-line:hover:before {
	content: "";
	display: block;
	position: absolute;
	top: 0;
	left: -12px;
	height: 100%;
}

body.showEditorSelection li.code-active-line:before,
body.showEditorSelection li.code-line:hover:before {
	left: -30px;
}

.vscode-light.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(0, 0, 0, 0.15);
}

.vscode-light.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(0, 0, 0, 0.40);
}

.vscode-light.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-dark.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 255, 255, 0.4);
}

.vscode-dark.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 255, 255, 0.60);
}

.vscode-dark.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-high-contrast.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 160, 0, 0.7);
}

.vscode-high-contrast.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 160, 0, 1);
}

.vscode-high-contrast.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

img {
	max-width: 100%;
	max-height: 100%;
}

a {
	text-decoration: none;
}

a:hover {
	text-decoration: underline;
}

a:focus,
input:focus,
select:focus,
textarea:focus {
	outline: 1px solid -webkit-focus-ring-color;
	outline-offset: -1px;
}

hr {
	border: 0;
	height: 2px;
	border-bottom: 2px solid;
}

h1 {
	padding-bottom: 0.3em;
	line-height: 1.2;
	border-bottom-width: 1px;
	border-bottom-style: solid;
}

h1, h2, h3 {
	font-weight: normal;
}

table {
	border-collapse: collapse;
}

table > thead > tr > th {
	text-align: left;
	border-bottom: 1px solid;
}

table > thead > tr > th,
table > thead > tr > td,
table > tbody > tr > th,
table > tbody > tr > td {
	padding: 5px 10px;
}

table > tbody > tr + tr > td {
	border-top: 1px solid;
}

blockquote {
	margin: 0 7px 0 5px;
	padding: 0 16px 0 10px;
	border-left-width: 5px;
	border-left-style: solid;
}

code {
	font-family: Menlo, Monaco, Consolas, "Droid Sans Mono", "Courier New", monospace, "Droid Sans Fallback";
	font-size: 1em;
	line-height: 1.357em;
}

body.wordWrap pre {
	white-space: pre-wrap;
}

pre:not(.hljs),
pre.hljs code > div {
	padding: 16px;
	border-radius: 3px;
	overflow: auto;
}

pre code {
	color: var(--vscode-editor-foreground);
	tab-size: 4;
}

/** Theming */

.vscode-light pre {
	background-color: rgba(220, 220, 220, 0.4);
}

.vscode-dark pre {
	background-color: rgba(10, 10, 10, 0.4);
}

.vscode-high-contrast pre {
	background-color: rgb(0, 0, 0);
}

.vscode-high-contrast h1 {
	border-color: rgb(0, 0, 0);
}

.vscode-light table > thead > tr > th {
	border-color: rgba(0, 0, 0, 0.69);
}

.vscode-dark table > thead > tr > th {
	border-color: rgba(255, 255, 255, 0.69);
}

.vscode-light h1,
.vscode-light hr,
.vscode-light table > tbody > tr + tr > td {
	border-color: rgba(0, 0, 0, 0.18);
}

.vscode-dark h1,
.vscode-dark hr,
.vscode-dark table > tbody > tr + tr > td {
	border-color: rgba(255, 255, 255, 0.18);
}

</style>

<style>
/* Tomorrow Theme */
/* http://jmblog.github.com/color-themes-for-google-code-highlightjs */
/* Original theme - https://github.com/chriskempson/tomorrow-theme */

/* Tomorrow Comment */
.hljs-comment,
.hljs-quote {
	color: #8e908c;
}

/* Tomorrow Red */
.hljs-variable,
.hljs-template-variable,
.hljs-tag,
.hljs-name,
.hljs-selector-id,
.hljs-selector-class,
.hljs-regexp,
.hljs-deletion {
	color: #c82829;
}

/* Tomorrow Orange */
.hljs-number,
.hljs-built_in,
.hljs-builtin-name,
.hljs-literal,
.hljs-type,
.hljs-params,
.hljs-meta,
.hljs-link {
	color: #f5871f;
}

/* Tomorrow Yellow */
.hljs-attribute {
	color: #eab700;
}

/* Tomorrow Green */
.hljs-string,
.hljs-symbol,
.hljs-bullet,
.hljs-addition {
	color: #718c00;
}

/* Tomorrow Blue */
.hljs-title,
.hljs-section {
	color: #4271ae;
}

/* Tomorrow Purple */
.hljs-keyword,
.hljs-selector-tag {
	color: #8959a8;
}

.hljs {
	display: block;
	overflow-x: auto;
	color: #4d4d4c;
	padding: 0.5em;
}

.hljs-emphasis {
	font-style: italic;
}

.hljs-strong {
	font-weight: bold;
}
</style>

<style>
/*
 * Markdown PDF CSS
 */

 body {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif, "Meiryo";
	padding: 0 12px;
}

pre {
	background-color: #f8f8f8;
	border: 1px solid #cccccc;
	border-radius: 3px;
	overflow-x: auto;
	white-space: pre-wrap;
	overflow-wrap: break-word;
}

pre:not(.hljs) {
	padding: 23px;
	line-height: 19px;
}

blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.emoji {
	height: 1.4em;
}

code {
	font-size: 14px;
	line-height: 19px;
}

/* for inline code */
:not(pre):not(.hljs) > code {
	color: #C9AE75; /* Change the old color so it seems less like an error */
	font-size: inherit;
}

/* Page Break : use <div class="page"/> to insert page break
-------------------------------------------------------- */
.page {
	page-break-after: always;
}

</style>

<script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
</head>
<body>
  <script>
    mermaid.initialize({
      startOnLoad: true,
      theme: document.body.classList.contains('vscode-dark') || document.body.classList.contains('vscode-high-contrast')
          ? 'dark'
          : 'default'
    });
  </script>
<h1 id="introduction">Introduction</h1>
<p>The United States Government Freedom of Information Act (FOIA) allows individual citizens the right to ask for and receive previously unreleased documents possessed by the Government upon request. Our project endeavors to see if there are any hidden patterns surrounding the origin of the so-called Unidentified Flying Objects (UFOs) that the Government hasn't disclosed before. We will apply our developed system to a series of PDF documents released by the Central Intelligence Agency (CIA) through a FOIA request to understand the text content better.</p>
<h1 id="source-data-collection">Source Data Collection</h1>
<p>Our goal is to use 713 Government-released documents that have been made available through the website &quot;The Black Vault.&quot; This site provides two sets of digital artifacts. The first is a zip of PDFs that have been made searchable from the original release by the authors of the website. The original source for these documents is also available in TIFF image form. An explanation of the artifacts and processing of each is further explained.</p>
<h1 id="data-conditioning-and-processing">Data Conditioning and Processing</h1>
<p>The backend data subsystem will be responsible for opening all PDF files within the specified directory, cleaning them as appropriate, and building the interim data products for the data processing pipeline.</p>
<ol>
<li>Documents are opened, tokenized, and imported into memory.</li>
<li>All tokenized words will be compared to a Wordnet, and only words with semantics will be indexed.</li>
<li>Only documents that ultimately have more than two actual words will be indexed.</li>
</ol>
<p>The team initially discovered upon using the processed PDFs made available by the above website that they inserted advertisements into the PDFs[^1]. These ads were causing false keywords to be inserted into the document and causing our statistics not to be valid. As a result, we returned to the source original TIFF images released by the CIA and reran Optical Character Recognition (OCR) on those documents[^2]. This OCR was run in batch mode through Adobe Acrobat Pro and was quite time-consuming; however, because of this work, all of our initial observations are much more accurate to the reality of parsing through Government released documents. These OCR-processed documents are available upon request.[^3]</p>
<p>Using the criteria listed, we are forced to eliminate 95 documents with no valuable content.</p>
<p>[^2]: Raw TIFF images from Government: <a href="https://documents2.theblackvault.com/documents/cia/CIAUFOCD-FULL-UNTOUCHED.zip">https://documents2.theblackvault.com/documents/cia/CIAUFOCD-FULL-UNTOUCHED.zip</a>
[^1]: Processed &quot;Searchable&quot; PDFs with Advertisement: <a href="https://documents2.theblackvault.com/documents/cia/CIAUFOCD-FULL-CONVERTED.zip">https://documents2.theblackvault.com/documents/cia/CIAUFOCD-FULL-CONVERTED.zip</a>
[^3]: Team GitHub with Data: <a href="https://github.com/johnemyers/iste-612/tree/main/data/CIA-MY-OCR">https://github.com/johnemyers/iste-612/tree/main/data/CIA-MY-OCR</a>
\newpage</p>
<h1 id="initial-observations">Initial Observations</h1>
<p>After parsing through the data using the documents produced and filtered as detailed above, we were able to establish a dictionary of 8,205 unique words within all the documents available. As seen in Figure \ref{WordCountHist}, we first looked at the overall distribution of word counts within the 618 documents that had useful content. There is a large concentration on the lower end, so there isn't a normal distribution. In addition, there are some extreme outliers on the upper end. The team doesn't feel that this distribution will negatively affect the research to be conducted in this case, as we did a fair amount of prepping of the dataset to get to this point.</p>
<p><img src="file:///c:/Users/UvirA/source/repos/iste-612/checkpoint-2/images/WordCountHist.png" alt="Histogram of Word Count\label{WordCountHist}"></p>
<p>After observing this distribution, we continued by computing the overall page word count summary statistics. The summary is seen in Table \ref{SummStatsWord} and shows that, on average over the 618 documents, we see ~238 words per document. While this mean is skewed by the single outlier document of 5392 words, a look at the offending document, <code>C05517512.pdf</code>, shows a relatively cleanly scanned document of the same relative type as the rest. Because of this, we don't feel even the median of 82 words causes this dataset to be invalid for our research.</p>
<table>
<thead>
<tr>
<th>count</th>
<th>mean</th>
<th>std</th>
<th>min</th>
<th>25%</th>
<th>50%</th>
<th>75%</th>
<th>max</th>
</tr>
</thead>
<tbody>
<tr>
<td>618</td>
<td>238.34</td>
<td>492.13</td>
<td>3</td>
<td>31.25</td>
<td>82</td>
<td>184.50</td>
<td>5392</td>
</tr>
</tbody>
</table>
<p>: Summary Statistics of Word Count\label{SummStatsWord}</p>
<p>\newpage</p>
<p>In addition, a line count was computed for each of the filtered documents (documents with at least three words). A series plot by Document ID/Name for the line count across the documents is shown in Figure \ref{lineCount}.</p>
<p><img src="file:///c:/Users/UvirA/source/repos/iste-612/checkpoint-2/images/LineCountSeriesPlot.png" alt="Line Count Series Plot\label{lineCount}"></p>
<p>The summary statistics for line count is also calculated to look at the distribution of the lines across the documents. The details are provided in Table \ref{SummStatsLine}. In many cases, the line count is greater than the word count because of the fact that there are several invalid lines in the document which were redacted. For example, the maximum number of lines found is in <code>C05516145.pdf</code> where most lines are unreadable.</p>
<table>
<thead>
<tr>
<th>count</th>
<th>mean</th>
<th>std</th>
<th>min</th>
<th>25%</th>
<th>50%</th>
<th>75%</th>
<th>max</th>
</tr>
</thead>
<tbody>
<tr>
<td>618</td>
<td>370.28</td>
<td>681.18</td>
<td>10</td>
<td>87</td>
<td>149.5</td>
<td>336.5</td>
<td>7427</td>
</tr>
</tbody>
</table>
<p>: Summary Statistics of Line Count\label{SummStatsLine}</p>
<p>Because documents have potentially degraded information due to both scanning quality and redactions inherent within FOIA-released documents, this measure helps ascertain the viability of text information within. We assess that between these two measures, this remains a reasonable dataset to continue our development on.</p>
<p>After the analysis of the word and line counts per document, we next wanted to look at some simple statistics related to frequent words seen within all of the documents. We can see in Figure \ref{FrequentWordsBar} that some not surprising words emerge at the top of this list. We see that <code>unclassified</code> appears the most number of times within the documents, at 2768 times, followed by <code>soviet</code> and <code>russian</code> at 2218 and 1345, respectively. This gives us reasonable assurance that our techniques and processes are in order, as these are obviously critical keywords to the domain we are in.</p>
<p><img src="file:///c:/Users/UvirA/source/repos/iste-612/checkpoint-2/images/FrequentWordsBar.png" alt="Top 25 Frequent Words\label{FrequentWordsBar}"></p>
<p>Now that we know we have a reasonable data processing pipeline for the backend, we can now begin to look at refining our software development approach and converge on what information retrieval and text mining operations can be applied for our entire application.</p>
<h1 id="methodology">Methodology</h1>
<p>We began looking at a high level of what clusters exist within the data when tokenizing actual English words within the documents.  Figure \ref{ElbowMethodOptimalK} shows the Sum of Square Distances for k-clusters where <code>k</code> is between 2 and 20.  If we choose a cluster size of 10 based upon the observations, Table \ref{Clusters} shows Word Clouds for four of those clusters. Further research will be conducted in this area in subsequent milestones to understand better what those clusters might indicate, as well as determine the similarity between documents within those clusters.</p>
<p><img src="file:///c:/Users/UvirA/source/repos/iste-612/checkpoint-2/images/ElbowMethodOptimalK.png" alt="Plot of 2-20 Clusters\label{ElbowMethodOptimalK}"></p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td><img src="file:///c:/Users/UvirA/source/repos/iste-612/checkpoint-2/images/186cc4fa-251d-47e7-9682-b65b949d8333.png" alt=""></td>
<td><img src="file:///c:/Users/UvirA/source/repos/iste-612/checkpoint-2/images/454d0e0f-3dc9-43dc-ae6c-fe96f44e0f3a.png" alt=""></td>
</tr>
<tr>
<td><img src="file:///c:/Users/UvirA/source/repos/iste-612/checkpoint-2/images/4ab90ea9-fcd9-4e03-af6e-f0a3cbdc3442.png" alt=""></td>
<td><img src="file:///c:/Users/UvirA/source/repos/iste-612/checkpoint-2/images/77e349f4-1cea-4d99-987a-b8d84bd80b6a.png" alt=""></td>
</tr>
</tbody>
</table>
<p>: Sample Word Clouds for Four Clusters\label{Clusters}</p>
<h1 id="conclusion">Conclusion</h1>
<p>AFter the initial analysis using K-means clustering, it was evident that the clusters did not map to the type of documents as expected. There was variability in cluster content observed between runs. Cluster #2 appeared to be consistently intact. All the 27 documents in this cluster were transcripts of Russian TV programs. Nearly all the documents are about the same size and quality whocih could have affected the cluster assignment more than the content. Almost all the &quot;High Quality&quot; documents were assigned to a couple of clusters, cluster #1, #8 and #9. Important predominate phrases were observed in multiple clusters (i.e., &quot;Unclassified&quot;, &quot;Air&quot;, &quot;Force&quot;) and this might indicate low cohesiveness within a cluster or help identify words with little value for the use case.</p>

</body>
</html>
